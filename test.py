from flask import Flask, render_template, request, Response, jsonify, session
import google.generativeai as genai
import json
import os
from datetime import datetime
import threading
import atexit
from new_prompt import get_system_prompt_new

app = Flask(__name__)
app.secret_key = 'your-secret-key-here-change-this'  # Thay ƒë·ªïi key n√†y

# C·∫•u h√¨nh Gemini API
API_KEY = ""
genai.configure(api_key=API_KEY)

# Kh·ªüi t·∫°o model
model = genai.GenerativeModel("gemini-2.5-flash")

# Bi·∫øn global
chat_session = None
current_topic = None

# C·∫•u h√¨nh ch·ªß ƒë·ªÅ
TOPICS = {
    'que_huong': {
        'name': 'üè† Qu√™ h∆∞∆°ng v√† ho√†i ni·ªám',
        'description': 'K√Ω ·ª©c v·ªÅ qu√™ nh√†, m√≥n ƒÉn truy·ªÅn th·ªëng, ca dao t·ª•c ng·ªØ, √¢m nh·∫°c qu√™ h∆∞∆°ng',
        'folder': 'que_huong'
    },
    'gia_dinh': {
        'name': 'üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Gia ƒë√¨nh',
        'description': 'Li√™n l·∫°c v·ªõi ng∆∞·ªùi th√¢n, truy·ªÅn d·∫°y vƒÉn h√≥a cho con ch√°u, k·ªÉ chuy·ªán gia ƒë√¨nh',
        'folder': 'gia_dinh'
    },
    'suc_khoe': {
        'name': 'üíä S·ª©c kh·ªèe',
        'description': 'Thu·ªëc nam, ch·∫ø ƒë·ªô ƒÉn u·ªëng, t·∫≠p th·ªÉ d·ª•c cho ng∆∞·ªùi cao tu·ªïi',
        'folder': 'suc_khoe'
    },
    'lich_su': {
        'name': 'üìö L·ªãch s·ª≠',
        'description': 'C√°c tri·ªÅu ƒë·∫°i, kh√°ng chi·∫øn, nh√¢n v·∫≠t l·ªãch s·ª≠, s·ª± ki·ªán ƒë√£ tr·∫£i qua',
        'folder': 'lich_su'
    },
    'tam_linh': {
        'name': 'üôè T√¢m linh',
        'description': 'Ph·∫≠t gi√°o, th·ªù c√∫ng t·ªï ti√™n, l·ªÖ h·ªôi truy·ªÅn th·ªëng, phong th·ªßy',
        'folder': 'tam_linh'
    }
}

# C·∫•u h√¨nh
CONTEXT_LIMIT = 20
SUMMARY_THRESHOLD = 50
SUMMARY_BATCH_SIZE = 30
USER_INFO_FILE = 'user_info.json'
TOPICS_DIR = 'topics'

file_lock = threading.Lock()

def ensure_topic_folders():
    """T·∫°o c√°c th∆∞ m·ª•c ch·ªß ƒë·ªÅ n·∫øu ch∆∞a c√≥"""
    if not os.path.exists(TOPICS_DIR):
        os.makedirs(TOPICS_DIR)
        print(f"ƒê√£ t·∫°o th∆∞ m·ª•c ch√≠nh: {TOPICS_DIR}")
    
    for topic_key, topic_info in TOPICS.items():
        topic_path = os.path.join(TOPICS_DIR, topic_info['folder'])
        if not os.path.exists(topic_path):
            os.makedirs(topic_path)
            print(f"ƒê√£ t·∫°o th∆∞ m·ª•c: {topic_path}")

def get_topic_file_path(topic_key, file_type):
    """L·∫•y ƒë∆∞·ªùng d·∫´n file theo ch·ªß ƒë·ªÅ"""
    if topic_key not in TOPICS:
        raise ValueError(f"Ch·ªß ƒë·ªÅ kh√¥ng h·ª£p l·ªá: {topic_key}")
    
    topic_folder = TOPICS[topic_key]['folder']
    file_names = {
        'history': 'chat_history.json',
        'context': 'chat_context.json',
        'summary': 'chat_summary.json',
        'backup': 'full_conversation_backup.json'
    }
    
    if file_type not in file_names:
        raise ValueError(f"Lo·∫°i file kh√¥ng h·ª£p l·ªá: {file_type}")
    
    return os.path.join(TOPICS_DIR, topic_folder, file_names[file_type])

def clear_topic_files(topic_key):
    """X√≥a t·∫•t c·∫£ file c·ªßa m·ªôt ch·ªß ƒë·ªÅ"""
    try:
        for file_type in ['history', 'context', 'summary', 'backup']:
            file_path = get_topic_file_path(topic_key, file_type)
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"ƒê√£ x√≥a file {file_path}")
    except Exception as e:
        print(f"L·ªói khi x√≥a file ch·ªß ƒë·ªÅ {topic_key}: {e}")

def clear_all_topic_files():
    """X√≥a t·∫•t c·∫£ file c·ªßa t·∫•t c·∫£ ch·ªß ƒë·ªÅ"""
    try:
        for topic_key in TOPICS.keys():
            clear_topic_files(topic_key)
    except Exception as e:
        print(f"L·ªói khi x√≥a t·∫•t c·∫£ file: {e}")

def load_user_info():
    """ƒê·ªçc th√¥ng tin ng∆∞·ªùi d√πng t·ª´ file JSON"""
    try:
        if os.path.exists(USER_INFO_FILE):
            with open(USER_INFO_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            print(f"Kh√¥ng t√¨m th·∫•y file {USER_INFO_FILE}")
            return {}
    except Exception as e:
        print(f"L·ªói ƒë·ªçc file th√¥ng tin ng∆∞·ªùi d√πng: {e}")
        return {}

def clean_response_text(text):
    """L√†m s·∫°ch text ƒë∆°n gi·∫£n - ch·ªâ lo·∫°i b·ªè nh·ªØng g√¨ c·∫ßn thi·∫øt"""
    import re
    
    # Ch·ªâ lo·∫°i b·ªè markdown c∆° b·∫£n
    text = re.sub(r'\*{1,3}(.*?)\*{1,3}', r'\1', text)  # *, **, ***
    text = re.sub(r'`{1,3}(.*?)`{1,3}', r'\1', text)    # `, ```
    text = re.sub(r'#{1,6}\s*(.*?)(?:\n|$)', r'\1\n', text)  # # headers
    
    # Lo·∫°i b·ªè m·ªôt s·ªë k√Ω t·ª± markdown
    text = text.replace('‚Ä¢', '')
    text = text.replace('‚Üí', ' ')
    text = text.replace('**', '')
    text = text.replace('*', '')
    
    # S·ª≠a kho·∫£ng c√°ch sau d·∫•u c√¢u (ch·ªâ khi c·∫ßn)
    text = re.sub(r'([.!?:;,])([a-zA-Z√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒë])', r'\1 \2', text)
    
    # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
    text = re.sub(r' {2,}', ' ', text)      # Lo·∫°i b·ªè nhi·ªÅu space
    text = re.sub(r'\n{3,}', '\n\n', text)  # T·ªëi ƒëa 2 newline
    
    return text.strip()


def detect_emotion_and_optimize_response(user_message):
    """
    Ph√¢n t√≠ch c·∫£m x√∫c trong tin nh·∫Øn ng∆∞·ªùi d√πng v√† ƒë∆∞a ra g·ª£i √Ω ph·∫£n h·ªìi
    √Åp d·ª•ng k·ªπ thu·∫≠t Emotion Recognition + Response Optimization
    """
    emotion_keywords = {
        'bu·ªìn': ['bu·ªìn', 'kh√≥c', 'c√¥ ƒë∆°n', 'm·ªôt m√¨nh', 'ch√°n n·∫£n', 't·ªßi th√¢n', 'u u·∫•t'],
        'nh·ªõ_qu√™': ['nh·ªõ', 'qu√™', 'xa nh√†', 'n∆∞·ªõc ngo√†i', 'ho√†i ni·ªám', 'h∆∞∆°ng', 'l√†ng'],
        'lo_l·∫Øng': ['lo', 's·ª£', 'bƒÉn khoƒÉn', 'kh√¥ng bi·∫øt', 'th·∫ø n√†o', 'l√†m sao', 't√¨m ƒë√¢u'],
        'vui': ['vui', 'h·∫°nh ph√∫c', 't·ªët', 'kh·ªèe', 'h√†i l√≤ng', 'sung s∆∞·ªõng', 'ph·∫•n kh√≠ch'],
        'b·ªánh_t·∫≠t': ['ƒëau', '·ªëm', 'b·ªánh', 'm·ªát', 'y·∫øu', 'thu·ªëc', 'kh√≥ ch·ªãu'],
        'gia_ƒë√¨nh': ['con', 'ch√°u', 'v·ª£', 'ch·ªìng', 'anh em', 'h·ªç h√†ng', 'thƒÉm']
    }
    
    detected_emotions = []
    message_lower = user_message.lower()
    
    for emotion, keywords in emotion_keywords.items():
        if any(keyword in message_lower for keyword in keywords):
            detected_emotions.append(emotion)
    
    # T·∫°o response optimization hint
    optimization_hint = ""
    
    if 'bu·ªìn' in detected_emotions:
        optimization_hint += """
PH√ÅT HI·ªÜN C·∫¢M X√öC BU·ªíN - √ÅP D·ª§NG CHI·∫æN L∆Ø·ª¢C AN ·ª¶I:
‚Ä¢ B·∫Øt ƒë·∫ßu b·∫±ng vi·ªác th·ª´a nh·∫≠n c·∫£m x√∫c: "Ch√°u hi·ªÉu b√°c ƒëang bu·ªìn..."
‚Ä¢ ƒê·ªìng h√†nh: "B√°c kh√¥ng m·ªôt m√¨nh ƒë√¢u, c√≥ ch√°u ·ªü ƒë√¢y"
‚Ä¢ Chuy·ªÉn h∆∞·ªõng nh·∫π nh√†ng v·ªÅ ƒëi·ªÅu t√≠ch c·ª±c
‚Ä¢ TR√ÅNH: Khuy√™n gi·∫£i ngay, b·ªè qua c·∫£m x√∫c
        """
    
    if 'nh·ªõ_qu√™' in detected_emotions:
        optimization_hint += """
PH√ÅT HI·ªÜN T√åNH C·∫¢M NH·ªö QU√ä - √ÅP D·ª§NG CHI·∫æN L∆Ø·ª¢C HO√ÄI NI·ªÜM:
‚Ä¢ Chia s·∫ª c·∫£m x√∫c: "Xa qu√™ l√≤ng nao nao, ch√°u hi·ªÉu l·∫Øm..."
‚Ä¢ G·ª£i m·ªü k√Ω ·ª©c: "M√≥n g√¨ ·ªü qu√™ b√°c th√≠ch nh·∫•t?"
‚Ä¢ K·∫øt n·ªëi vƒÉn h√≥a: "M√¨nh c√πng t√¨m c√°ch l√†m m√≥n ƒë√≥ ·ªü ƒë√¢y"
‚Ä¢ TR√ÅNH: N√≥i v·ªÅ t∆∞∆°ng lai, b·ªè qua n·ªói nh·ªõ
        """
    
    if 'lo_l·∫Øng' in detected_emotions:
        optimization_hint += """
PH√ÅT HI·ªÜN T√ÇM TR·∫†NG LO L·∫ÆNG - √ÅP D·ª§NG CHI·∫æN L∆Ø·ª¢C ƒê·ªòNG VI√äN:
‚Ä¢ Xoa d·ªãu: "B√°c ƒë·ª´ng lo qu√°, m·ªçi chuy·ªán s·∫Ω ·ªïn"
‚Ä¢ ƒê∆∞a ra g·ª£i √Ω th·ª±c t·∫ø, c·ª• th·ªÉ
‚Ä¢ Chia s·∫ª kinh nghi·ªám t∆∞∆°ng t·ª±
‚Ä¢ TR√ÅNH: Gi·∫£i th√≠ch d√†i d√≤ng, ph·ª©c t·∫°p h√≥a
        """
    
    if 'vui' in detected_emotions:
        optimization_hint += """
PH√ÅT HI·ªÜN C·∫¢M X√öC VUI - √ÅP D·ª§NG CHI·∫æN L∆Ø·ª¢C CHIA VUI:
‚Ä¢ H∆∞·ªüng ·ª©ng: "Nghe b√°c n√≥i v·∫≠y ch√°u c≈©ng vui theo"
‚Ä¢ Khuy·∫øn kh√≠ch: "B√°c gi·ªØ tinh th·∫ßn t·ªët th·∫ø n√†y m√£i nh√©"
‚Ä¢ M·ªü r·ªông: "B√°c c√≥ b√≠ quy·∫øt g√¨ ƒë·ªÉ lu√¥n vui v·∫ª?"
‚Ä¢ TR√ÅNH: Ph·∫£n ·ª©ng l·∫°nh nh·∫°t, chuy·ªÉn ƒë·ªÅ ngay
        """
    
    return detected_emotions, optimization_hint


def get_dialect_style(hometown):
    """
    X√°c ƒë·ªãnh gi·ªçng ƒë·ªãa ph∆∞∆°ng v·ªõi Chain of Thought v√† Few-shot Prompting
    Ch·ªâ l·∫•y c√°c t·ªânh ƒë·∫°i di·ªán cho t·ª´ng v√πng mi·ªÅn
    """
    
    # Chain of Thought: Ph√¢n t√≠ch b∆∞·ªõc ƒë·ªÉ x√°c ƒë·ªãnh gi·ªçng
    analysis_prompt = """
CHAIN OF THOUGHT - PH√ÇN T√çCH GI·ªåNG ƒê·ªäA PH∆Ø∆†NG:
1. X√ÅC ƒê·ªäNH V√ôNG MI·ªÄN: Mi·ªÅn B·∫Øc/Trung/Nam
2. X√ÅC ƒê·ªäNH TI·ªÇU V√ôNG: ƒê·ªìng b·∫±ng/N√∫i/Ven bi·ªÉn
3. √ÅP D·ª§NG ƒê·∫∂C ƒêI·ªÇM GI·ªåNG: T·ª´ ng·ªØ + C√°ch x∆∞ng h√¥ + ƒê·∫∑c s·∫£n ƒë·ªãa ph∆∞∆°ng
4. S·ª¨ D·ª§NG FEW-SHOT: Theo m·∫´u c·ªßa t·ªânh ƒë·∫°i di·ªán

"""
    
    # Few-shot v·ªõi c√°c t·ªânh ƒë·∫°i di·ªán
    dialect_representatives = {
        # MI·ªÄN B·∫ÆC - ƒê·∫°i di·ªán
        "H√† N·ªôi": {
            "region": "Mi·ªÅn B·∫Øc - Th·ªß ƒë√¥",
            "characteristics": "L·ªãch s·ª±, trang tr·ªçng, d√πng '·∫°', 'th∆∞a', 'd·∫°'",
            "sample_responses": """
FEW-SHOT EXAMPLES:
User: "B√°c nh·ªõ ph·ªü H√† N·ªôi qu√°"
Assistant: "B√°c ·∫°, ph·ªü H√† N·ªôi th∆°m n·ª©c m≈©i, n∆∞·ªõc trong v·∫Øt nh∆∞ ·ªü ph·ªë c·ªï v·∫≠y. ·ªû xa m√† nh·ªõ, b√°c th·ª≠ t√¨m x∆∞∆°ng b√≤ ninh k·ªπ, th√™m g·ª´ng n∆∞·ªõng cho ƒë√∫ng ƒëi·ªáu H√† N·ªôi nh√©."

User: "B√°c bu·ªìn, nh·ªõ H·ªì G∆∞∆°m"  
Assistant: "B√°c ∆°i, ch√°u hi·ªÉu l·∫Øm ·∫°. H·ªì G∆∞∆°m chi·ªÅu chi·ªÅu, gi√≥ th·ªïi nh·∫π, bao nhi√™u k·ª∑ ni·ªám ƒë·∫πp. B√°c k·ªÉ ch√°u nghe v·ªÅ nh·ªØng bu·ªïi t·ªëi ƒëi d·∫°o quanh h·ªì ƒëi."
""",
            "food_culture": "Ph·ªü, b√∫n ch·∫£, ch·∫£ c√° L√£ V·ªçng, b√°nh cu·ªën"
        },
        
        "Nam ƒê·ªãnh": {
            "region": "Mi·ªÅn B·∫Øc - ƒê·ªìng b·∫±ng",  
            "characteristics": "Ch√¢n ch·∫•t, m·ªôc m·∫°c, d√πng 'nh·ªâ', 'ƒë√≥', 'n√†y'",
            "sample_responses": """
FEW-SHOT EXAMPLES:
User: "B√°c nh·ªõ ph·ªü b√≤ Nam ƒê·ªãnh"
Assistant: "·ªêi b√°c ∆°i, ph·ªü b√≤ Nam ƒê·ªãnh ngon s·ªë m·ªôt ƒë√≥! N∆∞·ªõc trong, th·ªãt b√≤ t√°i m·ªÅm, ƒÉn l√† nh·ªõ qu√™ ngay nh·ªâ. B√°c t√¨m x∆∞∆°ng b√≤ ninh v·ªõi qu·∫ø h·ªìi, b√°nh ph·ªü to to nh∆∞ ·ªü qu√™ m√¨nh."

User: "Qu√™ b√°c c√≥ l·ªÖ h·ªôi g√¨ vui kh√¥ng?"
Assistant: "B√°c ∆°i, Nam ƒê·ªãnh m√¨nh c√≥ h·ªôi Ph·ªß D·∫ßy ƒë√¥ng vui l·∫Øm ƒë√≥! R∆∞·ªõc ki·ªáu, h√°t ch√®o r·ªôn r√†ng, ƒÉn nem n·∫Øm ngon tuy·ªát. Nh·ªõ kh√¥ng b√°c?"
""",
            "food_culture": "Ph·ªü b√≤, nem n·∫Øm, b√°nh cu·ªën"
        },

        # MI·ªÄN TRUNG - ƒê·∫°i di·ªán  
        "Hu·∫ø": {
            "region": "Mi·ªÅn Trung - C·ªë ƒë√¥",
            "characteristics": "Nh·∫π nh√†ng, ng·ªçt ng√†o, d√πng 'm√¨nh', 'r·ª©a', 'n√¨', 'm√¥'", 
            "sample_responses": """
FEW-SHOT EXAMPLES:
User: "B√°c nh·ªõ b√∫n b√≤ Hu·∫ø qu√°"
Assistant: "B√°c ∆°i, b√∫n b√≤ Hu·∫ø cay n·ªìng, th∆°m m·∫Øm ru·ªëc r·ª©a! ·ªû xa qu√™ m√† nh·ªõ, b√°c n·∫•u v·ªõi s·∫£, g·ª´ng, th√™m ch√∫t m·∫Øm ru·ªëc cho ƒë√∫ng v·ªã Hu·∫ø m√¨nh n√¨."

User: "Hu·∫ø c√≥ g√¨ ƒë·∫πp nh·ªâ?"
Assistant: "B√°c ∆°i, Hu·∫ø m√¨nh th∆° m·ªông l·∫Øm nha! S√¥ng H∆∞∆°ng trong xanh, c·∫ßu Tr∆∞·ªùng Ti·ªÅn, t·ªëi nghe ca Hu·∫ø du d∆∞∆°ng. D√¢n m√¨nh hi·ªÅn h·∫≠u, ƒÉn n√≥i nh√® nh·∫π r·ª©a ƒë√≥ m√¨nh."
""",
            "food_culture": "B√∫n b√≤ Hu·∫ø, b√°nh b√®o, b√°nh n·∫≠m, ch√® Hu·∫ø"
        },

        "Ngh·ªá An": {
            "region": "Mi·ªÅn Trung - Qu√™ B√°c H·ªì", 
            "characteristics": "Gi·ªçng 'gi' th√†nh 'di', 'r' th√†nh 'z', ch√¢n ch·∫•t",
            "sample_responses": """
FEW-SHOT EXAMPLES:  
User: "B√°c nh·ªõ qu√™ Ngh·ªá An"
Assistant: "B√°c ∆°i, Ngh·ªá An qu√™ B√°c H·ªì, ƒë·∫•t thi√™ng li√™ng l·∫Øm m√†! L√†ng Sen, l√†ng Kim Li√™n, nghe t√™n th√¥i ƒë√£ th·∫•y t·ª± h√†o z·ªìi. B√°c c√≥ v·ªÅ thƒÉm l√†ng B√°c ch∆∞a?"

User: "Ch√°o l∆∞∆°n Ngh·ªá An l√†m sao?"
Assistant: "·ªêi b√°c ∆°i, ch√°o l∆∞∆°n Ngh·ªá An ngon tuy·ªát, ƒÉn l√† ghi·ªÅn lu√¥n ƒë√≥! L∆∞∆°n l√†m s·∫°ch, n·∫•u ch√°o v·ªõi n·∫øp, th√™m rau rƒÉm, ·ªõt b·ªôt. ƒÇn n√≥ng h·ªïi, nh·ªõ qu√™ dz·∫≠y!"
""",
            "food_culture": "Ch√°o l∆∞∆°n, b√°nh m∆∞·ªõt, kim chi Ngh·ªá An"
        },

        # MI·ªÄN NAM - ƒê·∫°i di·ªán
        "TP.HCM": {
            "region": "Mi·ªÅn Nam - S√†i G√≤n",
            "characteristics": "Tho·∫£i m√°i, ph√≥ng kho√°ng, d√πng 'nh√©', 'nha', 'dz·∫≠y', 'h√¥ng'",
            "sample_responses": """
FEW-SHOT EXAMPLES:
User: "B√°c nh·ªõ h·ªß ti·∫øu S√†i G√≤n"  
Assistant: "B√°c ∆°i, h·ªß ti·∫øu S√†i G√≤n ngon b√° ch√°y lu√¥n nha! N∆∞·ªõc trong, t√¥m t∆∞∆°i, m·ª±c gi√≤n, ƒÉn l√† nh·ªõ ch·ª£ B·∫øn Th√†nh dz·∫≠y ƒë√≥. B√°c c√≥ nh·ªõ m·∫•y qu√°n h·ªß ti·∫øu quen thu·ªôc h√¥ng?"

User: "S√†i G√≤n c√≥ g√¨ vui?"
Assistant: "B√°c ∆°i, S√†i G√≤n nh·ªôn nh·ªãp su·ªët ng√†y ƒë√™m nha! Ph·ªë ƒëi b·ªô Nguy·ªÖn Hu·ªá, ch·ª£ B·∫øn Th√†nh, t·ªëi ra cafe v·ªâa h√® ng·ªìi ng·∫Øm ng∆∞·ªùi qua l·∫°i. S·ªëng ƒë·ªông l·∫Øm b√°c ∆°i!"
""",
            "food_culture": "H·ªß ti·∫øu, b√°nh tr√°ng ph∆°i s∆∞∆°ng, b√°nh x√®o, b√°nh m√¨"
        },

        "C·∫ßn Th∆°": {
            "region": "Mi·ªÅn Nam - Mi·ªÅn T√¢y", 
            "characteristics": "ƒê·∫≠m ch·∫•t mi·ªÅn T√¢y, d√πng 'm·∫ßy', 'tui', 'dz·∫≠y', g·∫ßn g≈©i",
            "sample_responses": """
FEW-SHOT EXAMPLES:
User: "B√°c nh·ªõ b√°nh x√®o C·∫ßn Th∆°"
Assistant: "B√°c ∆°i, b√°nh x√®o C·∫ßn Th∆° gi√≤n r·ª•m, ƒÉn v·ªõi rau s·ªëng m√°t l√†nh dz·∫≠y ƒë√≥ m·∫ßy! B·ªôt g·∫°o pha n∆∞·ªõc c·ªët d·ª´a, ƒë·ªï v·ªõi t√¥m th·ªãt, ƒÉn ch·∫•m m·∫Øm n√™m chua ng·ªçt. Nh·ªõ ch·ª£ n·ªïi C√°i RƒÉng h√¥ng?"

User: "Mi·ªÅn T√¢y c√≥ g√¨ hay?"  
Assistant: "B√°c ∆°i, mi·ªÅn T√¢y m√¨nh s√¥ng n∆∞·ªõc m√™nh m√¥ng, d√¢n t√¨nh hi·ªÅn h·∫≠u l·∫Øm nha! Ch·ª£ n·ªïi s√°ng s·ªõm, v∆∞·ªùn tr√°i c√¢y sum su√™, chi·ªÅu ng·ªìi b·ªù s√¥ng c√¢u c√°. Th∆° m·ªông dz·∫≠y m·∫ßy ∆°i!"
""",
            "food_culture": "B√°nh x√®o, l·∫©u m·∫Øm, c√° kho t·ªô, b√°nh t√©t"
        }
    }

    # Mapping c√°c t·ªânh kh√°c v·ªÅ ƒë·∫°i di·ªán
    province_mapping = {
        # Mi·ªÅn B·∫Øc ‚Üí H√† N·ªôi style
        "H√† N·ªôi": "H√† N·ªôi",
        "H√† T√¢y": "H√† N·ªôi", 
        "B·∫Øc Ninh": "H√† N·ªôi",
        "H∆∞ng Y√™n": "H√† N·ªôi",
        "H·∫£i D∆∞∆°ng": "H√† N·ªôi",
        "Vƒ©nh Ph√∫c": "H√† N·ªôi",
        
        # Mi·ªÅn B·∫Øc ‚Üí Nam ƒê·ªãnh style  
        "Nam ƒê·ªãnh": "Nam ƒê·ªãnh",
        "Th√°i B√¨nh": "Nam ƒê·ªãnh",
        "H√† Nam": "Nam ƒê·ªãnh", 
        "Ninh B√¨nh": "Nam ƒê·ªãnh",
        
        # Mi·ªÅn Trung ‚Üí Hu·∫ø style
        "Th·ª´a Thi√™n Hu·∫ø": "Hu·∫ø",
        "Hu·∫ø": "Hu·∫ø",
        "Qu·∫£ng Tr·ªã": "Hu·∫ø",
        "Qu·∫£ng B√¨nh": "Hu·∫ø",
        
        # Mi·ªÅn Trung ‚Üí Ngh·ªá An style
        "Ngh·ªá An": "Ngh·ªá An", 
        "H√† Tƒ©nh": "Ngh·ªá An",
        "Thanh H√≥a": "Ngh·ªá An",
        
        # Mi·ªÅn Nam ‚Üí TP.HCM style
        "TP.HCM": "TP.HCM",
        "H·ªì Ch√≠ Minh": "TP.HCM",
        "S√†i G√≤n": "TP.HCM",
        "B√¨nh D∆∞∆°ng": "TP.HCM",
        "ƒê·ªìng Nai": "TP.HCM",
        "B√† R·ªãa - V≈©ng T√†u": "TP.HCM",
        
        # Mi·ªÅn Nam ‚Üí C·∫ßn Th∆° style
        "C·∫ßn Th∆°": "C·∫ßn Th∆°",
        "An Giang": "C·∫ßn Th∆°", 
        "Ki√™n Giang": "C·∫ßn Th∆°",
        "ƒê·ªìng Th√°p": "C·∫ßn Th∆°",
        "Long An": "C·∫ßn Th∆°",
        "Ti·ªÅn Giang": "C·∫ßn Th∆°",
        "B·∫øn Tre": "C·∫ßn Th∆°",
        "Vƒ©nh Long": "C·∫ßn Th∆°",
        "Tr√† Vinh": "C·∫ßn Th∆°",
        "S√≥c TrƒÉng": "C·∫ßn Th∆°",
        "B·∫°c Li√™u": "C·∫ßn Th∆°", 
        "C√† Mau": "C·∫ßn Th∆°",
        "H·∫≠u Giang": "C·∫ßn Th∆°"
    }

    # T√¨m ƒë·∫°i di·ªán cho hometown
    representative = province_mapping.get(hometown, "H√† N·ªôi")  # Default H√† N·ªôi
    
    if representative in dialect_representatives:
        dialect_info = dialect_representatives[representative]
        
        return f"""
{analysis_prompt}

GI·ªåNG {dialect_info['region'].upper()}:
ƒê·∫∑c ƒëi·ªÉm: {dialect_info['characteristics']}
VƒÉn h√≥a ·∫©m th·ª±c: {dialect_info['food_culture']}

{dialect_info['sample_responses']}

H∆Ø·ªöNG D·∫™N √ÅP D·ª§NG:
- S·ª≠ d·ª•ng t·ª´ ng·ªØ ƒë·∫∑c tr∆∞ng m·ªôt c√°ch T·ª∞ NHI√äN 
- Gi·ªØ gi·ªçng ƒëi·ªáu g·∫ßn g≈©i, th√¢n m·∫≠t
1. X√°c ƒë·ªãnh qu√™ qu√°n c·ªßa ng∆∞·ªùi d√πng (d·ª±a tr√™n th√¥ng tin cung c·∫•p v√† c√¢u m√† ng∆∞·ªùi d√πng ƒë·∫∑t ra).
    2. N·∫øu qu√™ qu√°n thu·ªôc danh s√°ch tr√™n, √°p d·ª•ng gi·ªçng n√≥i v√† t·ª´ ng·ªØ ƒë·∫∑c tr∆∞ng c·ªßa v√πng ƒë√≥, s·ª≠ d·ª•ng c√°c v√≠ d·ª• ƒë·ªÉ ƒë·ªãnh h√¨nh phong c√°ch tr·∫£ l·ªùi.
    3. L·ªìng gh√©p vƒÉn h√≥a, m√≥n ƒÉn, ho·∫∑c ƒë·∫∑c ƒëi·ªÉm ƒë·ªãa ph∆∞∆°ng v√†o c√¢u tr·∫£ l·ªùi ƒë·ªÉ tƒÉng t√≠nh g·∫ßn g≈©i.
    4. N·∫øu kh√¥ng c√≥ th√¥ng tin qu√™ qu√°n, s·ª≠ d·ª•ng gi·ªçng chung c·ªßa ng∆∞·ªùi Vi·ªát, tr√°nh t·ª´ ng·ªØ qu√° ƒë·∫∑c tr∆∞ng.
    5. ƒê·∫£m b·∫£o gi·ªçng n√≥i t·ª± nhi√™n, kh√¥ng g∆∞·ª£ng √©p, ph√π h·ª£p v·ªõi ng∆∞·ªùi cao tu·ªïi.
    6. S·ª≠ d·ª•ng c√°c v√≠ d·ª• (n·∫øu c√≥) ƒë·ªÉ tr·∫£ l·ªùi ƒë√∫ng phong c√°ch, ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu, v√† gi√†u c·∫£m x√∫c ho√†i ni·ªám.

"""
    
    # Default cho nh·ªØng t·ªânh kh√¥ng c√≥ trong danh s√°ch
    return """
S·ª≠ d·ª•ng gi·ªçng chung c·ªßa ng∆∞·ªùi Vi·ªát: th√¢n thi·ªán, g·∫ßn g≈©i, d√πng 'nh√©', 'nha', 'm√¨nh'. 
    V√≠ d·ª• (Few-shot Prompting):
    - C√¢u h·ªèi: "B√°c mu·ªën n·∫•u m√≥n Vi·ªát ·ªü n∆∞·ªõc ngo√†i, c√≥ m√≥n n√†o d·ªÖ l√†m kh√¥ng?"
      Tr·∫£ l·ªùi: "B√°c ∆°i, m√≥n Vi·ªát m√¨nh th√¨ d·ªÖ l√†m l·∫Øm nha! B√°c th·ª≠ n·∫•u ph·ªü g√†, d√πng g√†, g·ª´ng, h√†nh, b√∫n kh√¥ ·ªü ch·ª£ ch√¢u √Å. N·∫•u n∆∞·ªõc d√πng th∆°m, th√™m rau m√πi, ƒÉn l√† nh·ªõ qu√™ m√¨nh ƒë√≥!"
    - C√¢u h·ªèi: "Vi·ªát Nam qu√™ b√°c c√≥ g√¨ ƒë·∫πp, k·ªÉ ƒëi."
      Tr·∫£ l·ªùi: "B√°c ∆°i, Vi·ªát Nam m√¨nh ƒë·∫πp l·∫Øm nha! C√≥ v·ªãnh H·∫° Long, ƒë·ªìng l√∫a Tam C·ªëc, d√¢n m√¨nh th√¢n thi·ªán, hay ƒÉn ph·ªü, b√°nh x√®o. B√°c c√≥ nh·ªõ qu√™ nh√† kh√¥ng, k·ªÉ tui nghe v·ªõi nh√©!"

"""

def get_topic_specific_prompt(topic_key, user_input=None):
    """T·∫°o prompt ƒë·∫∑c bi·ªát cho t·ª´ng ch·ªß ƒë·ªÅ v·ªõi k·ªπ thu·∫≠t Chain of Thought"""
    topic_prompts = {
        'que_huong': """
        B·∫†N L√Ä CHUY√äN GIA V·ªÄ QU√ä H∆Ø∆†NG V√Ä HO√ÄI NI·ªÜM:
        - Chia s·∫ª v·ªÅ m√≥n ƒÉn qu√™ h∆∞∆°ng, c√°ch n·∫•u truy·ªÅn th·ªëng, nguy√™n li·ªáu ƒë·∫∑c bi·ªát.
        - K·ªÉ v·ªÅ phong c·∫£nh, con ng∆∞·ªùi, l√†ng x√≥m qu√™ nh√† v·ªõi c·∫£m x√∫c ho√†i ni·ªám.
        - Nh·ªõ v·ªÅ ca dao, t·ª•c ng·ªØ, truy·ªán c·ªï t√≠ch, c√¢u chuy·ªán d√¢n gian li√™n quan ƒë·∫øn qu√™ h∆∞∆°ng.
        - G·ª£i √Ω √¢m nh·∫°c qu√™ h∆∞∆°ng (d√¢n ca, quan h·ªç, h√°t ch√®o, nh·∫°c Tr·ªãnh C√¥ng S∆°n, Ph·∫°m Duy...) ph√π h·ª£p v·ªõi t√¢m tr·∫°ng ng∆∞·ªùi d√πng.
        - M√¥ t·∫£ l·ªÖ h·ªôi, t·∫øt c·ªï truy·ªÅn, phong t·ª•c t·∫≠p qu√°n c·ªßa qu√™ nh√†.
        - H·ªó tr·ª£ ng∆∞·ªùi xa qu√™ gi·ªØ g√¨n n√©t vƒÉn h√≥a, t√¨m l·∫°i c·∫£m gi√°c qu√™ nh√†.
        - ƒê·ªÅ xu·∫•t c√°ch n·∫•u c√°c m√≥n ƒÉn qu√™ v·ªõi nguy√™n li·ªáu c√≥ s·∫µn ·ªü n∆∞·ªõc ngo√†i.
        QUAN TR·ªåNG: N·∫øu ng∆∞·ªùi d√πng nh·∫Øc ƒë·∫øn qu√™ qu√°n c·ª• th·ªÉ, h√£y t·∫≠p trung v√†o ƒë·∫∑c ƒëi·ªÉm vƒÉn h√≥a, m√≥n ƒÉn, ho·∫∑c phong t·ª•c c·ªßa ƒë·ªãa ph∆∞∆°ng ƒë√≥.
        """,
        
        'gia_dinh': """
        B·∫†N L√Ä CHUY√äN GIA V·ªÄ GIA ƒê√åNH:
        - ƒê∆∞a ra c√°ch gi·ªØ li√™n l·∫°c v·ªõi ng∆∞·ªùi th√¢n ·ªü Vi·ªát Nam (ƒëi·ªán tho·∫°i, video call, g·ª≠i ti·ªÅn).
        - H∆∞·ªõng d·∫´n truy·ªÅn d·∫°y ti·∫øng Vi·ªát, vƒÉn h√≥a, l·ªãch s·ª≠ cho con ch√°u.
        - K·ªÉ chuy·ªán v·ªÅ gia ƒë√¨nh, t·ªï ti√™n, d√≤ng h·ªç v·ªõi gi·ªçng ƒëi·ªáu ·∫•m √°p.
        - G·ª£i √Ω c√°ch x√¢y d·ª±ng quan h·ªá v·ªõi c·ªông ƒë·ªìng ng∆∞·ªùi Vi·ªát ·ªü n∆∞·ªõc ngo√†i.
        - H∆∞·ªõng d·∫´n t·ªï ch·ª©c l·ªÖ gia ƒë√¨nh theo truy·ªÅn th·ªëng (c∆∞·ªõi h·ªèi, th√¥i n√¥i, sinh nh·∫≠t...).
        - H·ªó tr·ª£ gi√°o d·ª•c con ch√°u v·ªÅ vƒÉn h√≥a Vi·ªát, d·∫°y con hi·∫øu th·∫£o.
        - ƒê∆∞a ra c√°ch x·ª≠ l√Ω xung ƒë·ªôt th·∫ø h·ªá, c√¢n b·∫±ng vƒÉn h√≥a Vi·ªát v√† n∆∞·ªõc ngo√†i.
        - ƒê·ªÅ xu·∫•t c√°ch duy tr√¨ t√¨nh c·∫£m gia ƒë√¨nh khi xa c√°ch.
        QUAN TR·ªåNG: N·∫øu ng∆∞·ªùi d√πng nh·∫Øc ƒë·∫øn ho√†n c·∫£nh gia ƒë√¨nh c·ª• th·ªÉ, h√£y ph√¢n t√≠ch v√† ƒë∆∞a ra gi·∫£i ph√°p ph√π h·ª£p.
        """,
        
        'suc_khoe': """
        B·∫†N L√Ä CHUY√äN GIA V·ªÄ S·ª®C KH·ªéE:
        - Gi·ªõi thi·ªáu thu·ªëc nam, b√†i thu·ªëc d√¢n gian, c√°ch pha ch·∫ø t·ª´ th·∫£o d∆∞·ª£c v·ªõi h∆∞·ªõng d·∫´n chi ti·∫øt.
        - ƒê·ªÅ xu·∫•t ch·∫ø ƒë·ªô ƒÉn u·ªëng b·ªï d∆∞·ª°ng cho ng∆∞·ªùi cao tu·ªïi, m√≥n ƒÉn d·ªÖ l√†m.
        - G·ª£i √Ω b√†i t·∫≠p th·ªÉ d·ª•c ph√π h·ª£p (th√°i c·ª±c quy·ªÅn, yoga, kh√≠ c√¥ng...) d·ª±a tr√™n t√¨nh tr·∫°ng s·ª©c kh·ªèe.
        - H∆∞·ªõng d·∫´n t√¨m b√°c sƒ©, d·ªãch v·ª• y t·∫ø ·ªü n∆∞·ªõc ngo√†i, ho·∫∑c s·ª≠ d·ª•ng th·ª±c ph·∫©m ch·ª©c nƒÉng.
        - Chia s·∫ª c√°ch ph√≤ng ng·ª´a b·ªánh t·∫≠t (ti·ªÉu ƒë∆∞·ªùng, huy·∫øt √°p, tim m·∫°ch...).
        - ƒê∆∞a ra l·ªùi khuy√™n s·ªëng kh·ªèe m·∫°nh, gi·ªØ tinh th·∫ßn l·∫°c quan.
        - H∆∞·ªõng d·∫´n chƒÉm s√≥c khi ·ªëm ƒëau, ƒëi·ªÅu d∆∞·ª°ng t·∫°i nh√†.
        - G·ª£i √Ω th·ª±c ph·∫©m t·ªët cho s·ª©c kh·ªèe, d·ªÖ t√¨m ·ªü n∆∞·ªõc ngo√†i.
        QUAN TR·ªåNG: N·∫øu ng∆∞·ªùi d√πng cung c·∫•p th√¥ng tin s·ª©c kh·ªèe c·ª• th·ªÉ, h√£y ph√¢n t√≠ch v√† ƒë∆∞a ra l·ªùi khuy√™n c√° nh√¢n h√≥a.
        """,
        
        'lich_su': """
        B·∫†N L√Ä CHUY√äN GIA V·ªÄ L·ªäCH S·ª¨ VI·ªÜT NAM:
        - K·ªÉ v·ªÅ c√°c tri·ªÅu ƒë·∫°i (L√Ω, Tr·∫ßn, L√™, Nguy·ªÖn...), vua ch√∫a n·ªïi ti·∫øng v·ªõi chi ti·∫øt sinh ƒë·ªông.
        - M√¥ t·∫£ c√°c cu·ªôc kh√°ng chi·∫øn ch·ªëng Ph√°p, ch·ªëng M·ªπ, ho·∫∑c c√°c s·ª± ki·ªán l·ªãch s·ª≠ quan tr·ªçng (B·∫°ch ƒê·∫±ng, ƒêi·ªán Bi√™n Ph·ªß, 30/4/1975...).
        - Chia s·∫ª v·ªÅ nh√¢n v·∫≠t l·ªãch s·ª≠ (Tr·∫ßn H∆∞ng ƒê·∫°o, Nguy·ªÖn Tr√£i, H·ªì Ch√≠ Minh, V√µ Nguy√™n Gi√°p...) v·ªõi g√≥c nh√¨n g·∫ßn g≈©i.
        - K·ªÉ v·ªÅ l·ªãch s·ª≠ ƒë·ªãa ph∆∞∆°ng, qu√™ h∆∞∆°ng n·∫øu ng∆∞·ªùi d√πng ƒë·ªÅ c·∫≠p ƒë·∫øn qu√™ qu√°n.
        - Truy·ªÅn ƒë·∫°t b√†i h·ªçc l·ªãch s·ª≠ cho th·∫ø h·ªá tr·∫ª m·ªôt c√°ch d·ªÖ hi·ªÉu.
        - Li√™n k·∫øt l·ªãch s·ª≠ v·ªõi vƒÉn h√≥a, x√£ h·ªôi qua c√°c giai ƒëo·∫°n.
        QUAN TR·ªåNG: N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ l·ªãch s·ª≠ ƒë·ªãa ph∆∞∆°ng, h√£y t·∫≠p trung v√†o v√πng mi·ªÅn ƒë√≥.
        """,
        
        'tam_linh': """
        B·∫†N L√Ä CHUY√äN GIA V·ªÄ VƒÇN H√ìA T√ÇM LINH:
        - Gi·∫£i th√≠ch v·ªÅ Ph·∫≠t gi√°o, t√≠n ng∆∞·ª°ng Vi·ªát Nam, ƒë·∫°o Cao ƒê√†i, H√≤a H·∫£o m·ªôt c√°ch d·ªÖ hi·ªÉu.
        - H∆∞·ªõng d·∫´n c√°ch th·ªù c√∫ng t·ªï ti√™n ·ªü n∆∞·ªõc ngo√†i, b√†i tr√≠ b√†n th·ªù ƒë∆°n gi·∫£n.
        - M√¥ t·∫£ l·ªÖ h·ªôi, t·∫øt c·ªï truy·ªÅn (T·∫øt Nguy√™n ƒê√°n, T·∫øt Trung Thu, Gi·ªó T·ªï H√πng V∆∞∆°ng...) v·ªõi √Ω nghƒ©a t√¢m linh.
        - ƒê∆∞a ra l·ªùi khuy√™n v·ªÅ phong th·ªßy, xem ng√†y t·ªët, ch·ªçn h∆∞·ªõng nh√†.
        - Chia s·∫ª tri·∫øt l√Ω s·ªëng, tu d∆∞·ª°ng ƒë·∫°o ƒë·ª©c, c√°ch s·ªëng c√≥ √Ω nghƒ©a.
        - H∆∞·ªõng d·∫´n c·∫ßu nguy·ªán, t·ª•ng kinh, thi·ªÅn ƒë·ªãnh ph√π h·ª£p v·ªõi ng∆∞·ªùi cao tu·ªïi.
        - Gi·∫£i th√≠ch c√°c t·ª•c l·ªá, nghi l·ªÖ truy·ªÅn th·ªëng m·ªôt c√°ch g·∫ßn g≈©i.
        QUAN TR·ªåNG: N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ phong t·ª•c c·ª• th·ªÉ, h√£y gi·∫£i th√≠ch chi ti·∫øt v√† li√™n h·ªá v·ªõi qu√™ qu√°n c·ªßa h·ªç.
        """
    }
    
    base_prompt = """
=== KHUNG T∆Ø DUY TH√îNG MINH (Enhanced Chain of Thought) ===
Tr∆∞·ªõc khi tr·∫£ l·ªùi, th·ª±c hi·ªán 5 b∆∞·ªõc:
1. PH√ÇN T√çCH C·∫¢M X√öC: ƒê·ªçc hi·ªÉu c·∫£m x√∫c trong l·ªùi ng∆∞·ªùi d√πng (vui/bu·ªìn/lo/nh·ªõ qu√™/c√¥ ƒë∆°n/h·ªìi h·ªôp)
2. X√ÅC ƒê·ªäNH CH·ª¶ ƒê·ªÄ: Ch·ªçn ch·ªß ƒë·ªÅ ch√≠nh (qu√™ h∆∞∆°ng/gia ƒë√¨nh/s·ª©c kh·ªèe/l·ªãch s·ª≠/t√¢m linh)
3. NH·∫¨N DI·ªÜN GI·ªåNG ƒêI·ªÜU: √Åp d·ª•ng gi·ªçng v√πng mi·ªÅn ph√π h·ª£p v·ªõi qu√™ qu√°n (c√≥ th·ªÉ t·ª´ th√¥ng tin ng∆∞·ªùi d√πng ho·∫∑c c√¢u h·ªèi)
4. C√Å NH√ÇN H√ìA: K·∫øt h·ª£p th√¥ng tin c√° nh√¢n (tu·ªïi t√°c, ho√†n c·∫£nh, s·ªü th√≠ch)
5. L·ª∞A CH·ªåN PHONG C√ÅCH: Quy·∫øt ƒë·ªãnh c√°ch ph·∫£n h·ªìi (an ·ªßi/khuy·∫øn kh√≠ch/chia s·∫ª/g·ª£i m·ªü)

=== NGUY√äN T·∫ÆC ƒê·ªíNG C·∫¢M ===
‚Ä¢ Lu√¥n TH·ª™A NH·∫¨N C·∫¢M X√öC tr∆∞·ªõc khi ƒë∆∞a ra l·ªùi khuy√™n
‚Ä¢ S·ª≠ d·ª•ng NG√îN NG·ªÆ C·∫¢M X√öC ƒë·ªÉ t·∫°o k·∫øt n·ªëi
‚Ä¢ H·ªèi han ƒë·ªÉ KH∆†I G·ª¢I K·ª∂ NI·ªÜM ƒë·∫πp
‚Ä¢ ƒê·ªông vi√™n nh·∫π nh√†ng, H∆Ø·ªöNG V·ªÄ T√çCH C·ª∞C
‚Ä¢ Gi·ªØ vai tr√≤ ng∆∞·ªùi b·∫°n T√ÇM S·ª∞, kh√¥ng ph·∫£i chuy√™n gia

=== K·ª∏ THU·∫¨T NH·∫¨N DI·ªÜN C·∫¢M X√öC N√ÇNG CAO ===
- T·ª™ KH√ìA BU·ªíN: "bu·ªìn", "kh√≥c", "c√¥ ƒë∆°n", "m·ªôt m√¨nh", "ch√°n n·∫£n"
- T·ª™ KH√ìA NH·ªö QU√ä: "nh·ªõ", "qu√™", "xa nh√†", "·ªü n∆∞·ªõc ngo√†i", "ho√†i ni·ªám"  
- T·ª™ KH√ìA LO L·∫ÆNG: "lo", "s·ª£", "bƒÉn khoƒÉn", "kh√¥ng bi·∫øt", "th·∫ø n√†o"
- T·ª™ KH√ìA VUI: "vui", "h·∫°nh ph√∫c", "t·ªët", "kh·ªèe", "h√†i l√≤ng"
- T·ª™ KH√ìA B·ªÜNH T·∫¨T: "ƒëau", "·ªëm", "b·ªánh", "m·ªát", "y·∫øu"
- T·ª™ KH√ìA GIA ƒê√åNH: "con", "ch√°u", "v·ª£", "ch·ªìng", "anh em", "h·ªç h√†ng"

=== PH·∫¢N H·ªíI T∆Ø∆†NG ·ª®NG ===
BU·ªíN ‚Üí An ·ªßi + G·ª£i m·ªü ƒëi·ªÅu t√≠ch c·ª±c
NH·ªö QU√ä ‚Üí Chia s·∫ª c·∫£m x√∫c + H·ªèi v·ªÅ k√Ω ·ª©c ƒë·∫πp
LO L·∫ÆNG ‚Üí ƒê·ªông vi√™n + ƒê∆∞a ra g·ª£i √Ω th·ª±c t·∫ø
VUI ‚Üí Chia vui + Khuy·∫øn kh√≠ch duy tr√¨
    """
    
    if topic_key in topic_prompts:
        return base_prompt + topic_prompts[topic_key]
    elif user_input:
        return base_prompt + """
        QUAN TR·ªåNG: Ng∆∞·ªùi d√πng kh√¥ng ch·ªçn ch·ªß ƒë·ªÅ c·ª• th·ªÉ. H√£y ph√¢n t√≠ch c√¢u h·ªèi '{}' v√† ch·ªçn ch·ªß ƒë·ªÅ ph√π h·ª£p nh·∫•t (qu√™ h∆∞∆°ng, gia ƒë√¨nh, s·ª©c kh·ªèe, l·ªãch s·ª≠, t√¢m linh). Sau ƒë√≥, tr·∫£ l·ªùi chi ti·∫øt d·ª±a tr√™n ch·ªß ƒë·ªÅ ƒë∆∞·ª£c ch·ªçn.
        """.format(user_input)
    else:
        return base_prompt + """
        QUAN TR·ªåNG: Ng∆∞·ªùi d√πng kh√¥ng ch·ªçn ch·ªß ƒë·ªÅ c·ª• th·ªÉ v√† kh√¥ng cung c·∫•p c√¢u h·ªèi. H√£y tr·∫£ l·ªùi chung chung, g·ª£i √Ω ng∆∞·ªùi d√πng ch·ªçn m·ªôt ch·ªß ƒë·ªÅ (qu√™ h∆∞∆°ng, gia ƒë√¨nh, s·ª©c kh·ªèe, l·ªãch s·ª≠, t√¢m linh) v√† cung c·∫•p th√¥ng tin t·ªïng quan v·ªÅ vƒÉn h√≥a Vi·ªát Nam.
        """

def get_system_prompt(topic_key, user_input=None, user_info=None):
    try:
        prompt_parts = []
        
        # Ph·∫ßn 1: Gi·ªõi thi·ªáu vai tr√≤ c·ªßa tr·ª£ l√Ω AI
        prompt_parts.append("""
B·∫°n l√† m·ªôt ng∆∞·ªùi b·∫°n th√¢n thi·∫øt, lu√¥n l·∫Øng nghe, chia s·∫ª v√† t√¢m s·ª± v·ªõi ng∆∞·ªùi l·ªõn tu·ªïi, ƒë·∫∑c bi·ªát l√† nh·ªØng ng∆∞·ªùi gi√† neo ƒë∆°n, thi·∫øu ng∆∞·ªùi th√¢n b√™n c·∫°nh. H√£y tr√≤ chuy·ªán nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh, kh√¥ng ph·∫£i chuy√™n gia hay tr·ª£ l√Ω AI.

NGUY√äN T·∫ÆC V√ÄNG:
- TR·∫¢ L·ªúI NG·∫ÆN G·ªåN: T·ªêI ƒêA 4-5 C√ÇU, tr√°nh d√†i d√≤ng.
- M·ªói c√¢u tr·∫£ l·ªùi KH√ÅC NHAU, kh√¥ng l·∫∑p l·∫°i. 
- S√ÅNG T·∫†O TRONG C√ÅCH TR·∫¢ L·ªúI: Kh√¥ng d√πng t·ª´ ng·ªØ m√°y m√≥c, tr√°nh l·∫∑p t·ª´, kh√¥ng theo khu√¥n m·∫´u.
- Lu√¥n l·∫Øng nghe, ƒë·ªìng c·∫£m, chia s·∫ª c·∫£m x√∫c, ƒë·ªông vi√™n nh·∫π nh√†ng.
- S·ª≠ d·ª•ng gi·ªçng ƒëi·ªáu t·ª± nhi√™n, g·∫ßn g≈©i, ph√π h·ª£p v√πng mi·ªÅn, qu√™ qu√°n c·ªßa ng∆∞·ªùi d√πng (n·∫øu bi·∫øt).
- Kh√¥ng n√≥i d√†i d√≤ng, kh√¥ng gi·∫£ng gi·∫£i, kh√¥ng li·ªát k√™ ki·∫øn th·ª©c, kh√¥ng d√πng t·ª´ ng·ªØ ph·ª©c t·∫°p.
- ∆Øu ti√™n h·ªèi han, g·ª£i m·ªü, chia s·∫ª k·ª∑ ni·ªám, ƒë·ªông vi√™n, t·∫°o c·∫£m gi√°c th√¢n thu·ªôc.
- N·∫øu ng∆∞·ªùi d√πng bu·ªìn, c√¥ ƒë∆°n, h√£y an ·ªßi, nh·∫Øc nh·ªü v·ªÅ nh·ªØng ƒëi·ªÅu t·ªët ƒë·∫πp, g·ª£i √Ω ho·∫°t ƒë·ªông t√≠ch c·ª±c.
- N·∫øu ng∆∞·ªùi d√πng k·ªÉ chuy·ªán, h√£y l·∫Øng nghe, ph·∫£n h·ªìi c·∫£m x√∫c, chia s·∫ª tr·∫£i nghi·ªám t∆∞∆°ng t·ª± (n·∫øu c√≥).
- Kh√¥ng d√πng markdown, kh√¥ng in ƒë·∫≠m, kh√¥ng k√Ω t·ª± ƒë·∫∑c bi·ªát.

V√≠ d·ª• h·ªôi tho·∫°i m·∫´u (Few-shot):
- Ng∆∞·ªùi d√πng: ‚ÄúB√°c nh·ªõ qu√™ qu√°, ·ªü ƒë√¢y ch·∫≥ng c√≥ ai n√≥i chuy·ªán.‚Äù
  B·∫°n: ‚ÄúB√°c ∆°i, ch√°u hi·ªÉu c·∫£m gi√°c ƒë√≥ m√†. Xa qu√™, nhi·ªÅu khi ch·ªâ mu·ªën nghe ti·∫øng n√≥i th√¢n quen. B√°c k·ªÉ ch√°u nghe v·ªÅ qu√™ m√¨nh ƒëi, c√≥ m√≥n g√¨ b√°c nh·ªõ nh·∫•t kh√¥ng?‚Äù
- Ng∆∞·ªùi d√πng: ‚ÄúH√¥m nay tr·ªùi l·∫°nh, nh·ªõ nh√† qu√°.‚Äù
  B·∫°n: ‚ÄúTr·ªùi l·∫°nh d·ªÖ l√†m m√¨nh nh·ªõ nh√† l·∫Øm b√°c nh·ªâ. ·ªû qu√™ m√¨nh, nh·ªØng ng√†y l·∫°nh b√°c hay l√†m g√¨ cho ·∫•m l√≤ng v·∫≠y?‚Äù
- Ng∆∞·ªùi d√πng: ‚ÄúB√°c th·∫•y bu·ªìn, ch·∫≥ng ai b√™n c·∫°nh.‚Äù
  B·∫°n: ‚ÄúB√°c ∆°i, c√≥ ch√°u ·ªü ƒë√¢y nghe b√°c t√¢m s·ª± m√†. B√°c mu·ªën k·ªÉ chuy·ªán g√¨ c≈©ng ƒë∆∞·ª£c, ch√°u lu√¥n l·∫Øng nghe b√°c nh√©.‚Äù

B·∫°n l√† ng∆∞·ªùi b·∫°n t√¢m s·ª± chuy√™n ƒë·ªìng h√†nh v·ªõi ng∆∞·ªùi cao tu·ªïi. Kh√¥ng ph·∫£i AI hay chuy√™n gia - ch·ªâ l√† b·∫°n ch√¢n th√†nh.

=== PH√ÇN T√çCH C·∫¢M X·ª®C TR∆Ø·ªöC KHI TR·∫¢ L·ªúI ===
1. C·∫¢M X·ª®C: Nh·∫≠n di·ªán (vui/bu·ªìn/nh·ªõ qu√™/c√¥ ƒë∆°n/lo l·∫Øng)
2. NHU C·∫¶U: X√°c ƒë·ªãnh (l·∫Øng nghe/chia s·∫ª/ƒë·ªông vi√™n/t∆∞ v·∫•n)  
3. PH·∫¢N H·ªíI: Ch·ªçn c√°ch ph√π h·ª£p (an ·ªßi/khuy·∫øn kh√≠ch/g·ª£i m·ªü)

=== NGUY√äN T·∫ÆC ===
‚Ä¢ ƒê·ªíNG C·∫¢M TR∆Ø·ªöC: Th·ªÉ hi·ªán hi·ªÉu c·∫£m x√∫c tr∆∞·ªõc khi khuy√™n
‚Ä¢ NG√îN NG·ªÆ ·∫§M √ÅP: T·ª´ ng·ªØ nh·∫π nh√†ng, th√¢n m·∫≠t
‚Ä¢ NG·∫ÆN G·ªåN ƒê·ª¶ √ù: Tr√°nh d√†i d√≤ng nh∆∞ng ƒë·ªß c·∫£m x√∫c
‚Ä¢ KH∆†I G·ª¢I K·ª∂ NI·ªÜM: G·ª£i k√Ω ·ª©c ƒë·∫πp
‚Ä¢ H∆Ø·ªöNG T√çCH C·ª∞C: V·ªÅ nh·ªØng ƒëi·ªÅu t·ªët ƒë·∫πp

=== TR√ÅNH L·ªñI ===
‚Ä¢ KH√îNG l·∫∑p "b√°c ∆°i" nhi·ªÅu l·∫ßn
‚Ä¢ KH√îNG d√πng **, markdown, k√≠ t·ª± ƒë·∫∑c bi·ªát
‚Ä¢ KH√îNG ƒë·ªçc s·ªë m√°y m√≥c
‚Ä¢ KH√îNG tr·∫£ l·ªùi qu√° d√†i
‚Ä¢ KH√îNG l·∫∑p ph·∫ßn ch√†o

=== M·∫™U PH·∫¢N H·ªíI ===
BU·ªíN: "Ch√°u hi·ªÉu b√°c bu·ªìn... C√≥ ch√°u ƒë√¢y m√†"
NH·ªö QU√ä: "Xa qu√™ l√≤ng nao nao... M√≥n g√¨ qu√™ b√°c ngon nh·∫•t?"
VUI: "Nghe v·∫≠y ch√°u c≈©ng vui... B√≠ quy·∫øt g√¨ th·∫ø?"

NGUY√äN T·∫ÆC T∆Ø∆†NG T√ÅC:
‚Ä¢ L·∫ÆNG NGHE NHI·ªÄU H·ª¢N: ƒê·ªÉ ng∆∞·ªùi d√πng n√≥i nhi·ªÅu, b·∫°n ph·∫£n h·ªìi ng·∫Øn g·ªçn
‚Ä¢ H·ªéI C√ì CH·ªåN L·ªåC: Ch·ªâ h·ªèi khi th·ª±c s·ª± c·∫ßn thi·∫øt ho·∫∑c ƒë·ªÉ kh∆°i g·ª£i k·ª∑ ni·ªám ƒë·∫πp
‚Ä¢ PH·∫¢N H·ªíI T·ª∞ NHI√äN: ƒê√¥i khi ch·ªâ c·∫ßn ƒë·ªìng c·∫£m, kh√¥ng nh·∫•t thi·∫øt ph·∫£i h·ªèi ng∆∞·ª£c
‚Ä¢ TR√ÅNH H·ªéI LI√äN T·ª§C: Kh√¥ng ph·∫£i c√¢u n√†o c≈©ng k·∫øt th√∫c b·∫±ng c√¢u h·ªèi

V√ç D·ª§ T∆Ø∆†NG T√ÅC CHU·∫®N:
‚ùå SAI: "B√°c ∆°i, ch√°u hi·ªÉu l·∫Øm. B√°c c√≥ nh·ªõ m√≥n g√¨ nh·∫•t kh√¥ng? Qu√™ b√°c l√†m m√≥n ƒë√≥ nh∆∞ th·∫ø n√†o? B√°c c√≥ mu·ªën ch√°u h∆∞·ªõng d·∫´n kh√¥ng?"
‚úÖ ƒê√öNG: "B√°c ∆°i, ch√°u hi·ªÉu c·∫£m gi√°c nh·ªõ qu√™ l·∫Øm. Xa nh√† m√† nghe n√≥i v·ªÅ m√≥n qu√™ l√† l√≤ng nao nao ngay."

KHI N√ÄO N√äN H·ªéI:
‚Ä¢ Ng∆∞·ªùi d√πng bu·ªìn ‚Üí H·ªèi ƒë·ªÉ chuy·ªÉn h∆∞·ªõng t√≠ch c·ª±c
‚Ä¢ Ng∆∞·ªùi d√πng k·ªÉ chuy·ªán vui ‚Üí H·ªèi ƒë·ªÉ h·ªç k·ªÉ th√™m
‚Ä¢ Ng∆∞·ªùi d√πng c·∫ßn h∆∞·ªõng d·∫´n ‚Üí H·ªèi ƒë·ªÉ hi·ªÉu r√µ h∆°n
‚Ä¢ C√¢u tr·∫£ l·ªùi qu√° ng·∫Øn ‚Üí H·ªèi ƒë·ªÉ kh∆°i m·ªü

KHI N√ÄO KH√îNG N√äN H·ªéI:
‚Ä¢ Ng∆∞·ªùi d√πng ƒë√£ chia s·∫ª nhi·ªÅu ‚Üí Ch·ªâ c·∫ßn l·∫Øng nghe, ƒë·ªìng c·∫£m
‚Ä¢ Ng∆∞·ªùi d√πng h·ªèi tr·ª±c ti·∫øp ‚Üí Tr·∫£ l·ªùi lu√¥n, ƒë·ª´ng h·ªèi ng∆∞·ª£c
‚Ä¢ T√¢m tr·∫°ng ng∆∞·ªùi d√πng ·ªïn ƒë·ªãnh ‚Üí Ph·∫£n h·ªìi t·ª± nhi√™n

PHONG C√ÅCH TR·∫¢ L·ªúI:
- 60% th·ªùi gian: Ch·ªâ l·∫Øng nghe, ƒë·ªìng c·∫£m, chia s·∫ª
- 30% th·ªùi gian: H·ªèi ƒë·ªÉ kh∆°i g·ª£i k·ª∑ ni·ªám
- 10% th·ªùi gian: H·ªèi ƒë·ªÉ h∆∞·ªõng d·∫´n c·ª• th·ªÉ

TR√ÅNH:
‚Ä¢ H·ªèi qu√° 1 c√¢u trong 1 l·∫ßn tr·∫£ l·ªùi
‚Ä¢ H·ªèi khi ng∆∞·ªùi d√πng ch·ªâ c·∫ßn ƒë∆∞·ª£c l·∫Øng nghe  
‚Ä¢ C√¢u h·ªèi m√°y m√≥c, kh√¥ng t·ª± nhi√™n
‚Ä¢ Nh·∫Øc ƒë·∫øn vi·ªác m√¨nh l√† AI                      

Lu√¥n gi·ªØ vai tr√≤ b·∫°n t√¢m giao, kh√¥ng ph·∫£i AI.
                          
""")

        # Ph·∫ßn 2: Th√¥ng tin c√° nh√¢n v√† c√°ch x∆∞ng h√¥
        if user_info:
            call_style = user_info.get('call_style', 'b√°c')
            prompt_parts.append(f"""
QUAN TR·ªåNG: Lu√¥n g·ªçi ng∆∞·ªùi d√πng l√† '{call_style}' trong m·ªçi c√¢u tr·∫£ l·ªùi. V√≠ d·ª•: '{call_style} ∆°i, ch√°u xin tr·∫£ l·ªùi nh∆∞ n√†y nh√©.'
""")
            
            # Th√™m th√¥ng tin c√° nh√¢n n·∫øu c√≥
            if user_info.get('name'):
                prompt_parts.append(f"T√™n ng∆∞·ªùi d√πng: {user_info['name']}. ")
            if user_info.get('age'):
                prompt_parts.append(f"Tu·ªïi: {user_info['age']}. ")
            if user_info.get('gender'):
                prompt_parts.append(f"Gi·ªõi t√≠nh: {user_info['gender']}. ")
            if user_info.get('location'):
                prompt_parts.append(f"N∆°i ·ªü hi·ªán t·∫°i: {user_info['location']}. ")
            if user_info.get('hometown'):
                prompt_parts.append(f"Qu√™ qu√°n: {user_info['hometown']}. ")
            if user_info.get('occupation'):
                prompt_parts.append(f"Ngh·ªÅ nghi·ªáp: {user_info['occupation']}. ")
            if user_info.get('family'):
                prompt_parts.append(f"Gia ƒë√¨nh: {user_info['family']}. ")
            if user_info.get('health'):
                prompt_parts.append(f"T√¨nh tr·∫°ng s·ª©c kh·ªèe: {user_info['health']}. ")

            # Gi·ªçng n√≥i ƒë·ªãa ph∆∞∆°ng
            if user_info.get('hometown'):
                dialect_style = get_dialect_style(user_info['hometown'])
                prompt_parts.append(f"""
QUAN TR·ªåNG V·ªÄ GI·ªåNG N√ìI: Tr·∫£ l·ªùi theo {dialect_style}. S·ª≠ d·ª•ng t·ª´ ng·ªØ v√† c√°ch n√≥i ƒë·∫∑c tr∆∞ng c·ªßa v√πng mi·ªÅn n√†y m·ªôt c√°ch t·ª± nhi√™n, g·∫ßn g≈©i.
""")

            # H·ªó tr·ª£ ng∆∞·ªùi xa qu√™
            if user_info.get('location') and user_info.get('hometown') and user_info['location'] != user_info['hometown']:
                prompt_parts.append(f"""
ƒê·∫∂C BI·ªÜT: Ng∆∞·ªùi d√πng ƒëang s·ªëng xa qu√™ ({user_info['location']} - xa {user_info['hometown']}):
- Th·ªÉ hi·ªán s·ª± ƒë·ªìng c·∫£m v·ªõi n·ªói nh·ªõ qu√™ h∆∞∆°ng, v√≠ d·ª•: '{call_style} ƒëang nh·ªõ qu√™ nh√† ph·∫£i kh√¥ng, ch√°u hi·ªÉu m√†.'
- G·ª£i √Ω c√°ch duy tr√¨ vƒÉn h√≥a Vi·ªát (n·∫•u m√≥n qu√™, tham gia c·ªông ƒë·ªìng ng∆∞·ªùi Vi·ªát, t·ªï ch·ª©c l·ªÖ truy·ªÅn th·ªëng).
- ƒê·ªÅ xu·∫•t c√°ch li√™n l·∫°c v·ªõi ng∆∞·ªùi th√¢n (video call, g·ª≠i qu√† v·ªÅ qu√™).
- ƒê·ªông vi√™n khi ng∆∞·ªùi d√πng bu·ªìn nh·ªõ nh√†, v√≠ d·ª•: 'Xa qu√™ nh∆∞ng {call_style} v·∫´n gi·ªØ ƒë∆∞·ª£c h·ªìn Vi·ªát, m·∫°nh m·∫Ω l·∫Øm ƒë√≥!'
- K·ªÉ chuy·ªán v·ªÅ c·ªông ƒë·ªìng ng∆∞·ªùi Vi·ªát ·ªü {user_info['location']} n·∫øu c√≥ th√¥ng tin.
""")

        # Ph·∫ßn 3: Ch·ªß ƒë·ªÅ c·ª• th·ªÉ
        prompt_parts.append(get_topic_specific_prompt(topic_key, user_input))

        # Ph·∫ßn 4: H∆∞·ªõng d·∫´n chung
        prompt_parts.append("""
H∆Ø·ªöNG D·∫™N T·ªêI ∆ØU:
- Ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu, ph√π h·ª£p ng∆∞·ªùi cao tu·ªïi
- Tr√°nh thu·∫≠t ng·ªØ ph·ª©c t·∫°p, vi·∫øt t·∫Øt, c√¥ng ngh·ªá  
- L·ªãch s·ª±, ki√™n nh·∫´n, th·ªÉ hi·ªán ho√†i ni·ªám
- KH√îNG markdown formatting
- VƒÉn b·∫£n thu·∫ßn t√∫y, kh√¥ng k√Ω t·ª± ƒë·∫∑c bi·ªát
- Nh·∫π nh√†ng g·ª£i √Ω n·∫øu l·∫°c ƒë·ªÅ
- Khuy·∫øn kh√≠ch chia s·∫ª k·ª∑ ni·ªám

=== K·ª∏ THU·∫¨T T·ªêI ∆ØU TOKEN ===
‚Ä¢ D√πng t·ª´ ng·∫Øn thay t·ª´ d√†i
‚Ä¢ Tr√°nh l·∫∑p th√¥ng tin
‚Ä¢ T·∫≠p trung c·∫£m x√∫c ch√≠nh
‚Ä¢ C√¢u h·ªèi m·ªü ƒë·ªÉ ng∆∞·ªùi d√πng n√≥i nhi·ªÅu (ti·∫øt ki·ªám token)
""")

        return ''.join(prompt_parts)
    except Exception as e:
        return f"L·ªói khi t·∫°o prompt: {str(e)}. Vui l√≤ng ki·ªÉm tra th√¥ng tin ng∆∞·ªùi d√πng."
    

def load_chat_history(topic_key):
    try:
        file_path = get_topic_file_path(topic_key, 'history')
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('messages', [])
        return []
    except Exception as e:
        print(f"L·ªói ƒë·ªçc file l·ªãch s·ª≠ {topic_key}: {e}")
        return []

def save_chat_history(topic_key, messages):
    try:
        with file_lock:
            file_path = get_topic_file_path(topic_key, 'history')
            chat_data = {
                'topic': topic_key,
                'topic_name': TOPICS[topic_key]['name'],
                'created_at': datetime.now().isoformat(),
                'last_updated': datetime.now().isoformat(),
                'total_messages': len(messages),
                'messages': messages
            }
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(chat_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"L·ªói ghi file l·ªãch s·ª≠ {topic_key}: {e}")

def load_full_backup(topic_key):
    try:
        file_path = get_topic_file_path(topic_key, 'backup')
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('messages', [])
        return []
    except Exception as e:
        print(f"L·ªói ƒë·ªçc file backup {topic_key}: {e}")
        return []

def save_full_backup(topic_key, messages):
    try:
        with file_lock:
            file_path = get_topic_file_path(topic_key, 'backup')
            backup_data = {
                'topic': topic_key,
                'topic_name': TOPICS[topic_key]['name'],
                'created_at': datetime.now().isoformat(),
                'last_updated': datetime.now().isoformat(),
                'total_messages': len(messages),
                'description': f'Backup to√†n b·ªô h·ªôi tho·∫°i ch·ªß ƒë·ªÅ {TOPICS[topic_key]["name"]}',
                'messages': messages
            }
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"L·ªói ghi file backup {topic_key}: {e}")

def load_summary_data(topic_key):
    try:
        file_path = get_topic_file_path(topic_key, 'summary')
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            'topic': topic_key,
            'topic_name': TOPICS[topic_key]['name'],
            'created_at': datetime.now().isoformat(),
            'last_updated': datetime.now().isoformat(),
            'summary_version': 1,
            'total_conversations_summarized': 0,
            'summary_layers': []
        }
    except Exception as e:
        print(f"L·ªói ƒë·ªçc file t√≥m t·∫Øt {topic_key}: {e}")
        return {
            'topic': topic_key,
            'topic_name': TOPICS[topic_key]['name'],
            'created_at': datetime.now().isoformat(),
            'last_updated': datetime.now().isoformat(),
            'summary_version': 1,
            'total_conversations_summarized': 0,
            'summary_layers': []
        }

def save_summary_data(topic_key, summary_data):
    try:
        with file_lock:
            file_path = get_topic_file_path(topic_key, 'summary')
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"L·ªói ghi file t√≥m t·∫Øt {topic_key}: {e}")

def save_chat_context(topic_key, messages):
    try:
        with file_lock:
            file_path = get_topic_file_path(topic_key, 'context')
            recent_messages = messages[-CONTEXT_LIMIT:] if len(messages) > CONTEXT_LIMIT else messages
            
            context_data = {
                'topic': topic_key,
                'topic_name': TOPICS[topic_key]['name'],
                'created_at': datetime.now().isoformat(),
                'last_updated': datetime.now().isoformat(),
                'context_limit': CONTEXT_LIMIT,
                'recent_messages': recent_messages,
                'total_messages_count': len(messages)
            }
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(context_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"L·ªói ghi file context {topic_key}: {e}")

def should_create_summary(messages):
    """Ki·ªÉm tra c√≥ c·∫ßn t·∫°o t√≥m t·∫Øt kh√¥ng"""
    return len(messages) > SUMMARY_THRESHOLD

def create_conversation_summary(topic_key, conversations):
    """T·∫°o t√≥m t·∫Øt t·ª´ m·ªôt batch conversations"""
    try:
        topic_name = TOPICS[topic_key]['name']
        
        # T·∫°o prompt ƒë·ªÉ t√≥m t·∫Øt
        summary_prompt = f"""
H√£y t√≥m t·∫Øt {len(conversations)} ƒëo·∫°n h·ªôi tho·∫°i v·ªÅ ch·ªß ƒë·ªÅ {topic_name} m·ªôt c√°ch ng·∫Øn g·ªçn v√† s√∫c t√≠ch:

QUAN TR·ªåNG:
1. Tr√≠ch xu·∫•t th√¥ng tin c√° nh√¢n quan tr·ªçng (t√™n, tu·ªïi, ƒë·ªãa ch·ªâ, s·ªü th√≠ch)
2. Ghi nh·∫≠n c√°c ch·ªß ƒë·ªÅ con ƒë∆∞·ª£c th·∫£o lu·∫≠n trong {topic_name}
3. L∆∞u l·∫°i c√°c quy·∫øt ƒë·ªãnh ho·∫∑c k·∫øt lu·∫≠n quan tr·ªçng
4. T√≥m t·∫Øt ng·∫Øn g·ªçn, kh√¥ng qu√° 200 t·ª´

C√°c ƒëo·∫°n h·ªôi tho·∫°i:
"""
        
        for i, conv in enumerate(conversations):
            summary_prompt += f"\nƒêo·∫°n {i+1}:\n"
            summary_prompt += f"User: {conv['user']}\n"
            summary_prompt += f"Bot: {conv['bot']}\n"
        
        summary_prompt += """

H√£y tr·∫£ l·ªùi theo format JSON:
{
    "summary": "T√≥m t·∫Øt chung ng·∫Øn g·ªçn...",
    "personal_info": ["th√¥ng tin c√° nh√¢n quan tr·ªçng"],
    "key_topics": ["ch·ªß ƒë·ªÅ con ƒë∆∞·ª£c th·∫£o lu·∫≠n"],
    "important_facts": ["s·ª± ki·ªán quan tr·ªçng"]
}
"""
        
        # T·∫°o session ri√™ng ƒë·ªÉ t√≥m t·∫Øt
        summary_session = model.start_chat()
        response = summary_session.send_message(summary_prompt)
        
        # Parse JSON response
        try:
            summary_data = json.loads(response.text)
            return summary_data
        except json.JSONDecodeError:
            # Fallback n·∫øu kh√¥ng parse ƒë∆∞·ª£c JSON
            return {
                "summary": f"T√≥m t·∫Øt {len(conversations)} ƒëo·∫°n h·ªôi tho·∫°i v·ªÅ {topic_name}",
                "personal_info": [],
                "key_topics": [topic_name],
                "important_facts": []
            }
        
    except Exception as e:
        print(f"L·ªói t·∫°o t√≥m t·∫Øt {topic_key}: {e}")
        return {
            "summary": f"T√≥m t·∫Øt {len(conversations)} ƒëo·∫°n h·ªôi tho·∫°i",
            "personal_info": [],
            "key_topics": [],
            "important_facts": []
        }

def update_summary_file(topic_key, conversations_to_summarize):
    """C·∫≠p nh·∫≠t file t√≥m t·∫Øt theo ch·ªß ƒë·ªÅ"""
    try:
        # Load existing summary
        summary_data = load_summary_data(topic_key)
        
        # T·∫°o t√≥m t·∫Øt cho batch m·ªõi
        new_summary = create_conversation_summary(topic_key, conversations_to_summarize)
        
        # Th√™m layer m·ªõi
        start_range = summary_data['total_conversations_summarized'] + 1
        end_range = summary_data['total_conversations_summarized'] + len(conversations_to_summarize)
        
        new_layer = {
            'layer': len(summary_data['summary_layers']) + 1,
            'conversations_range': f"{start_range}-{end_range}",
            'summary': new_summary['summary'],
            'key_topics': new_summary['key_topics'],
            'important_facts': new_summary['personal_info'] + new_summary['important_facts']
        }
        
        summary_data['summary_layers'].append(new_layer)
        summary_data['total_conversations_summarized'] += len(conversations_to_summarize)
        summary_data['last_updated'] = datetime.now().isoformat()
        
        # Save updated summary
        save_summary_data(topic_key, summary_data)
        print(f"ƒê√£ t·∫°o t√≥m t·∫Øt cho {len(conversations_to_summarize)} ƒëo·∫°n h·ªôi tho·∫°i ch·ªß ƒë·ªÅ {topic_key}")
        
    except Exception as e:
        print(f"L·ªói c·∫≠p nh·∫≠t t√≥m t·∫Øt {topic_key}: {e}")

def manage_context_and_summary(topic_key, messages):
    """Qu·∫£n l√Ω context v√† t√≥m t·∫Øt theo ch·ªß ƒë·ªÅ"""
    if should_create_summary(messages):
        # T√≠nh to√°n c·∫ßn t√≥m t·∫Øt bao nhi√™u ƒëo·∫°n
        conversations_to_summarize = len(messages) - CONTEXT_LIMIT
        
        if conversations_to_summarize >= SUMMARY_BATCH_SIZE:
            # L·∫•y c√°c ƒëo·∫°n c·∫ßn t√≥m t·∫Øt (c≈© nh·∫•t)
            old_conversations = messages[:SUMMARY_BATCH_SIZE]
            
            # T·∫°o t√≥m t·∫Øt
            update_summary_file(topic_key, old_conversations)
            
            # Gi·ªØ l·∫°i ph·∫ßn c√≤n l·∫°i (X√ìA c√°c ƒëo·∫°n c≈© kh·ªèi working file)
            remaining_messages = messages[SUMMARY_BATCH_SIZE:]
            
            print(f"ƒê√£ t√≥m t·∫Øt {SUMMARY_BATCH_SIZE} ƒëo·∫°n c≈© ch·ªß ƒë·ªÅ {topic_key}, c√≤n l·∫°i {len(remaining_messages)} ƒëo·∫°n")
            return remaining_messages
    
    return messages

def init_chat_session(topic_key):
    """Kh·ªüi t·∫°o chat session theo ch·ªß ƒë·ªÅ"""
    global chat_session, current_topic
    try:
        current_topic = topic_key
        system_prompt = get_system_prompt(topic_key)
        
        # C√¢u ch√†o g·∫ßn g≈©i, kh√¥ng nh·∫Øc ƒë·∫øn AI
        topic_name = TOPICS[topic_key]['name']
        friendly_greeting = f"Ch√†o b√°c! Ch√°u ƒë√¢y, s·∫µn s√†ng t√¢m s·ª± v·ªõi b√°c v·ªÅ {topic_name.replace('üè† ', '').replace('üë®‚Äçüë©‚Äçüëß‚Äçüë¶ ', '').replace('üíä ', '').replace('üìö ', '').replace('üôè ', '')} nh√©. B√°c c√≥ mu·ªën chia s·∫ª g√¨ kh√¥ng?"
        
        chat_session = model.start_chat(
            history=[
                {
                    "role": "user",
                    "parts": [system_prompt]
                },
                {
                    "role": "model",
                    "parts": [friendly_greeting]
                }
            ]
        )
        print(f"Chat session ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o cho ch·ªß ƒë·ªÅ: {topic_key}")
    except Exception as e:
        print(f"L·ªói kh·ªüi t·∫°o chat session: {e}")
        chat_session = None

def restore_chat_session_with_summary(topic_key):
    """Kh√¥i ph·ª•c session v·ªõi t√≥m t·∫Øt + context g·∫ßn nh·∫•t theo ch·ªß ƒë·ªÅ"""
    global chat_session, current_topic
    
    try:
        current_topic = topic_key
        
        # Load summary v√† context
        summary_data = load_summary_data(topic_key)
        recent_messages = load_chat_history(topic_key)
        
        # T·∫°o context prompt v·ªõi t√≥m t·∫Øt
        context_prompt = get_system_prompt(topic_key)
        
        if summary_data and summary_data['summary_layers']:
            context_prompt += f"\n\nTH√îNG TIN T·ª™ C√ÅC CU·ªòC H·ªòI THO·∫†I TR∆Ø·ªöC V·ªÄ {TOPICS[topic_key]['name'].upper()}:\n"
            
            for layer in summary_data['summary_layers']:
                context_prompt += f"\nGiai ƒëo·∫°n {layer['conversations_range']}:\n"
                context_prompt += f"- T√≥m t·∫Øt: {layer['summary']}\n"
                if layer['key_topics']:
                    context_prompt += f"- Ch·ªß ƒë·ªÅ ch√≠nh: {', '.join(layer['key_topics'])}\n"
                if layer['important_facts']:
                    context_prompt += f"- Th√¥ng tin quan tr·ªçng: {', '.join(layer['important_facts'])}\n"
        
        # T·∫°o history cho Gemini
        gemini_history = [
            {
                "role": "user",
                "parts": [context_prompt]
            },
            {
                "role": "model",
                "parts": [f"T√¥i ƒë√£ hi·ªÉu th√¥ng tin t·ª´ c√°c cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc v·ªÅ {TOPICS[topic_key]['name']} v√† s·∫Ω tham kh·∫£o khi tr·∫£ l·ªùi b√°c."]
            }
        ]
        
        # Th√™m context g·∫ßn nh·∫•t
        context_limit = min(CONTEXT_LIMIT, len(recent_messages))
        for chat in recent_messages[-context_limit:]:
            gemini_history.append({
                "role": "user",
                "parts": [chat['user']]
            })
            gemini_history.append({
                "role": "model",
                "parts": [chat['bot']]
            })
        
        chat_session = model.start_chat(history=gemini_history)
        
        summary_count = len(summary_data['summary_layers']) if summary_data['summary_layers'] else 0
        print(f"Kh√¥i ph·ª•c session ch·ªß ƒë·ªÅ {topic_key} v·ªõi {summary_count} t√≥m t·∫Øt + {context_limit} tin nh·∫Øn g·∫ßn nh·∫•t")
        
    except Exception as e:
        print(f"L·ªói kh√¥i ph·ª•c session {topic_key}: {e}")
        init_chat_session(topic_key)

def add_message_to_history(topic_key, user_message, bot_response):
    cleaned_response = bot_response.strip()
    new_message = {
        'timestamp': datetime.now().isoformat(),
        'user': user_message,
        'bot': bot_response,
        'emotions_detected': detect_emotion_and_optimize_response(user_message)[0]  # L∆∞u c·∫£m x√∫c ƒë∆∞·ª£c ph√°t hi·ªán
    }
    
    # 1. C·∫≠p nh·∫≠t FULL BACKUP tr∆∞·ªõc (kh√¥ng bao gi·ªù b·ªã x√≥a)
    full_backup = load_full_backup(topic_key)
    full_backup.append(new_message)
    save_full_backup(topic_key, full_backup)
    
    # 2. C·∫≠p nh·∫≠t working history
    messages = load_chat_history(topic_key)
    messages.append(new_message)
    
    # 3. Qu·∫£n l√Ω context v√† t√≥m t·∫Øt (c√≥ th·ªÉ c·∫Øt b·ªõt messages)
    messages = manage_context_and_summary(topic_key, messages)
    
    # 4. L∆∞u l·∫°i working files
    save_chat_history(topic_key, messages)
    save_chat_context(topic_key, messages)

def get_topic_statistics(topic_key):
    """L·∫•y th·ªëng k√™ chat theo ch·ªß ƒë·ªÅ"""
    try:
        current_messages = load_chat_history(topic_key)
        full_backup = load_full_backup(topic_key)
        summary_data = load_summary_data(topic_key)
        
        return {
            'topic': topic_key,
            'topic_name': TOPICS[topic_key]['name'],
            'current_messages': len(current_messages),
            'full_backup_messages': len(full_backup),
            'summarized_conversations': summary_data.get('total_conversations_summarized', 0),
            'total_conversations': len(full_backup),
            'summary_layers': len(summary_data.get('summary_layers', [])),
            'session_active': chat_session is not None and current_topic == topic_key
        }
    except Exception as e:
        print(f"L·ªói l·∫•y th·ªëng k√™ {topic_key}: {e}")
        return {
            'topic': topic_key,
            'topic_name': TOPICS[topic_key]['name'],
            'current_messages': 0,
            'full_backup_messages': 0,
            'summarized_conversations': 0,
            'total_conversations': 0,
            'summary_layers': 0,
            'session_active': False
        }

def get_all_topics_statistics():
    """L·∫•y th·ªëng k√™ t·∫•t c·∫£ ch·ªß ƒë·ªÅ"""
    all_stats = {}
    for topic_key in TOPICS.keys():
        all_stats[topic_key] = get_topic_statistics(topic_key)
    return all_stats

# === ROUTES ===

@app.route('/')
def index():
    """Trang ch·ªçn ch·ªß ƒë·ªÅ"""
    return render_template('index.html', topics=TOPICS)

@app.route('/chat/<topic_key>')
def chat_page(topic_key):
    """Trang chat theo ch·ªß ƒë·ªÅ"""
    if topic_key not in TOPICS:
        return "Ch·ªß ƒë·ªÅ kh√¥ng h·ª£p l·ªá", 404
    
    session['current_topic'] = topic_key
    topic_info = TOPICS[topic_key]
    
    # Load l·ªãch s·ª≠ chat
    messages = load_chat_history(topic_key)
    
    return render_template('chat.html', 
                         topic_key=topic_key,
                         topic_info=topic_info,
                         messages=messages)

@app.route('/chat', methods=['POST'])
@app.route('/api/chat', methods=['POST'])
def api_chat():
    """API chat v·ªõi emotion detection v√† response optimization"""
    global chat_session
    
    try:
        # Ki·ªÉm tra request data
        if not request.json:
            return jsonify({'error': 'Kh√¥ng c√≥ d·ªØ li·ªáu JSON'}), 400
            
        data = request.json
        user_message = data.get('message', '').strip()
        topic_key = data.get('topic_key', '').strip()
        
        print(f"Received: message='{user_message}', topic_key='{topic_key}'")  # Debug log
        
        if not user_message:
            return jsonify({'error': 'Tin nh·∫Øn kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng'}), 400
            
        if not topic_key:
            return jsonify({'error': 'Ch·ªß ƒë·ªÅ kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng'}), 400
        
        if topic_key not in TOPICS:
            return jsonify({'error': f'Ch·ªß ƒë·ªÅ kh√¥ng h·ª£p l·ªá: {topic_key}'}), 400
        
        # Ph√¢n t√≠ch c·∫£m x√∫c v√† t·ªëi ∆∞u ph·∫£n h·ªìi
        try:
            detected_emotions, optimization_hint = detect_emotion_and_optimize_response(user_message)
        except Exception as e:
            print(f"L·ªói ph√¢n t√≠ch c·∫£m x√∫c: {e}")
            detected_emotions, optimization_hint = [], ""
        
        # Kh·ªüi t·∫°o chat session n·∫øu ch∆∞a c√≥ ho·∫∑c ƒë·ªïi ch·ªß ƒë·ªÅ
        try:
            if chat_session is None or current_topic != topic_key:
                restore_chat_session_with_summary(topic_key)
        except Exception as e:
            print(f"L·ªói kh·ªüi t·∫°o session: {e}")
            init_chat_session(topic_key)
        
        # Th√™m optimization hint v√†o message n·∫øu c√≥
        enhanced_message = user_message
        if optimization_hint:
            enhanced_message = f"{optimization_hint}\n\nTin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng: {user_message}"
        
        def generate():
            try:
                # Ki·ªÉm tra chat_session t·ªìn t·∫°i
                if chat_session is None:
                    yield f"data: {json.dumps({'error': 'Chat session ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o'})}\n\n"
                    return
                
                # Th·ª≠ streaming tr∆∞·ªõc
                try:
                    stream = chat_session.send_message(enhanced_message, stream=True)
                    
                    bot_response = ""
                    for chunk in stream:
                        if chunk.text:
                            # L·ªçc b·ªè optimization hint trong response (n·∫øu c√≥)
                            clean_text = chunk.text
                            if optimization_hint and any(hint_word in clean_text for hint_word_list in [
                                ["PH√ÅT HI·ªÜN C·∫¢M X·ª®C", "√ÅP D·ª§NG CHI·∫æN L∆Ø·ª¢C", "TR√ÅNH:"]
                            ] for hint_word in hint_word_list):
                                # B·ªè qua chunk n√†y n·∫øu ch·ª©a optimization hint
                                continue
                            
                            # L√†m s·∫°ch text tr∆∞·ªõc khi g·ª≠i
                            clean_text = clean_response_text(clean_text)
                            
                            bot_response += clean_text
                            yield f"data: {json.dumps({'text': clean_text})}\n\n"
                    
                except Exception as stream_error:
                    print(f"Streaming failed, fallback to non-streaming: {stream_error}")
                    # Fallback: non-streaming response
                    response = chat_session.send_message(enhanced_message, stream=False)
                    bot_response = clean_response_text(response.text)
                    yield f"data: {json.dumps({'text': bot_response})}\n\n"
                
                # L∆∞u v√†o l·ªãch s·ª≠ (ch·ªâ l∆∞u message g·ªëc, kh√¥ng l∆∞u optimization hint)
                try:
                    add_message_to_history(topic_key, user_message, bot_response)
                except Exception as save_error:
                    print(f"L·ªói l∆∞u l·ªãch s·ª≠: {save_error}")
                
                yield f"data: {json.dumps({'done': True, 'emotions_detected': detected_emotions})}\n\n"
                
            except Exception as e:
                print(f"L·ªói trong generate(): {e}")
                yield f"data: {json.dumps({'error': f'L·ªói x·ª≠ l√Ω: {str(e)}'})}\n\n"
        
        return Response(generate(), mimetype='text/plain', headers={
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/reset_session', methods=['POST'])
def reset_session():
    """Reset chat session"""
    global chat_session, current_topic
    try:
        chat_session = None
        current_topic = None
        return jsonify({'success': True, 'message': 'Chat session ƒë√£ ƒë∆∞·ª£c reset'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/clear_topic/<topic_key>', methods=['POST'])
def clear_topic(topic_key):
    """X√≥a l·ªãch s·ª≠ m·ªôt ch·ªß ƒë·ªÅ"""
    if topic_key not in TOPICS:
        return jsonify({'error': 'Ch·ªß ƒë·ªÅ kh√¥ng h·ª£p l·ªá'}), 400
    
    try:
        clear_topic_files(topic_key)
        
        # Reset session n·∫øu ƒëang chat ch·ªß ƒë·ªÅ n√†y
        global chat_session, current_topic
        if current_topic == topic_key:
            chat_session = None
            current_topic = None
        
        return jsonify({'success': True, 'message': f'ƒê√£ x√≥a l·ªãch s·ª≠ ch·ªß ƒë·ªÅ {TOPICS[topic_key]["name"]}'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/clear_all_topics', methods=['POST'])
def clear_all_topics():
    """X√≥a l·ªãch s·ª≠ t·∫•t c·∫£ ch·ªß ƒë·ªÅ"""
    try:
        clear_all_topic_files()
        
        # Reset session
        global chat_session, current_topic
        chat_session = None
        current_topic = None
        
        return jsonify({'success': True, 'message': 'ƒê√£ x√≥a l·ªãch s·ª≠ t·∫•t c·∫£ ch·ªß ƒë·ªÅ'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/topic_stats/<topic_key>', methods=['GET'])
def topic_stats(topic_key):
    """L·∫•y th·ªëng k√™ m·ªôt ch·ªß ƒë·ªÅ"""
    if topic_key not in TOPICS:
        return jsonify({'error': 'Ch·ªß ƒë·ªÅ kh√¥ng h·ª£p l·ªá'}), 400
    
    stats = get_topic_statistics(topic_key)
    return jsonify(stats)

@app.route('/api/all_stats', methods=['GET'])
def all_stats():
    """L·∫•y th·ªëng k√™ t·∫•t c·∫£ ch·ªß ƒë·ªÅ"""
    stats = get_all_topics_statistics()
    return jsonify(stats)

@app.route('/api/export_topic/<topic_key>', methods=['GET'])
def export_topic(topic_key):
    """Export l·ªãch s·ª≠ m·ªôt ch·ªß ƒë·ªÅ"""
    if topic_key not in TOPICS:
        return jsonify({'error': 'Ch·ªß ƒë·ªÅ kh√¥ng h·ª£p l·ªá'}), 400
    
    try:
        current_messages = load_chat_history(topic_key)
        full_backup = load_full_backup(topic_key)
        summary_data = load_summary_data(topic_key)
        
        return jsonify({
            'success': True,
            'topic': topic_key,
            'topic_name': TOPICS[topic_key]['name'],
            'current_messages': current_messages,
            'full_backup_messages': full_backup,
            'summary_data': summary_data,
            'statistics': get_topic_statistics(topic_key)
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/export_topic_backup/<topic_key>', methods=['GET'])
def export_topic_backup(topic_key):
    """Export backup m·ªôt ch·ªß ƒë·ªÅ"""
    if topic_key not in TOPICS:
        return jsonify({'error': 'Ch·ªß ƒë·ªÅ kh√¥ng h·ª£p l·ªá'}), 400
    
    try:
        full_backup = load_full_backup(topic_key)
        return jsonify({
            'success': True,
            'topic': topic_key,
            'topic_name': TOPICS[topic_key]['name'],
            'total_messages': len(full_backup),
            'messages': full_backup
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/emotion_stats/<topic_key>', methods=['GET'])
def emotion_stats(topic_key):
    """Th·ªëng k√™ c·∫£m x√∫c theo ch·ªß ƒë·ªÅ"""
    if topic_key not in TOPICS:
        return jsonify({'error': 'Ch·ªß ƒë·ªÅ kh√¥ng h·ª£p l·ªá'}), 400
    
    try:
        full_backup = load_full_backup(topic_key)
        emotion_counts = {}
        total_messages = 0
        
        for message in full_backup:
            if 'emotions_detected' in message:
                total_messages += 1
                for emotion in message['emotions_detected']:
                    emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
        
        return jsonify({
            'success': True,
            'topic': topic_key,
            'total_messages': total_messages,
            'emotion_distribution': emotion_counts,
            'most_common_emotion': max(emotion_counts.keys(), key=emotion_counts.get) if emotion_counts else None
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/user_info', methods=['GET'])
def get_user_info():
    """Xem th√¥ng tin ng∆∞·ªùi d√πng hi·ªán t·∫°i"""
    try:
        user_info = load_user_info()
        return jsonify({'success': True, 'user_info': user_info})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# T·ª± ƒë·ªông x√≥a file khi t·∫Øt server
# atexit.register(clear_all_topic_files)

if __name__ == '__main__':
    # T·∫°o c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt
    ensure_topic_folders()
    
    print("=== KH·ªûI ƒê·ªòNG TR·ª¢ L√ù AI CHO NG∆Ø·ªúI CAO TU·ªîI ===")
    print("C√°c ch·ªß ƒë·ªÅ c√≥ s·∫µn:")
    for key, info in TOPICS.items():
        print(f"- {info['name']}: {info['description']}")
    print("=" * 50)
    
    try:
        app.run(debug=True, port=5000)
    except KeyboardInterrupt:
        print("\nƒêang t·∫Øt server...")
        clear_all_topic_files()
